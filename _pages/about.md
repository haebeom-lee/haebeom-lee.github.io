---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---
I'm a Ph.D candidate at [Machine Learning and Artificial Intelligence (MLAI) lab](https://www.mlai-kaist.com/) in KAIST, under the supervision of [Prof. Sung Ju Hwang](http://www.sungjuhwang.com/). I finished my B.S. degree at UNIST in 2016, and M.S. degree at UNIST in 2018 under the supervision of Prof. Sung Ju Hwang. My expected graduation date is August 2022.

## Research Interest
The ultimate goal of my research is contributing to human-level __artificial general intelligence__ (AGI). One of the most central aspects of AGI is its ability to generalize to novel tasks, and in order to understand this ability I have explored __meta-learning__, a higher-level learning framework that allows a model to learn to generalize over a distribution of tasks rather than generalize within a single task. During my Ph.D. study I have tried to extend the scope of meta-learning towards more realistic, practical, and large-scale scenarios. For future research agenda, I aim to study __meta-reinforcement learning__ (meta-RL) and __meta-continual learning__ (meta-CL) to better understand the way human being interact with the environments. Based on those understandings I aim to develop a human-level RL agent that can generalize to out-of-distribution tasks and continually learn from them. This is closely related to the concept of __system 2 deep learning__ (DL), which, from the meta-learning point of view, can be realized by incorporating higher-level __cognitive__ concepts into the __meta-knowledge structure__.

## Contact
haebeom dot lee at kaist dot ac dot kr



## Awards
- Global Ph.D Fellowship Program, 2019-2021
- Google Ph.D Fellowship Program 2021
 

## Conference Publications

- <font size="4">Online Hyperparameter Meta-Learning with Hypergradient Distillation</font>
[[paper]](http://arxiv.org/abs/2110.02508) \\
 **Hae Beom Lee**, Hayeon Lee, Jaewoong Shin, Eunho Yang, Timothy M. Hospedales, Sung Ju Hwang \\
<span style="color:darkred">**ICLR**</span> 2022 <span style="color:darkred">**(spotlight)**</span>

- <font size="4">Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning</font>
[[paper]](https://arxiv.org/abs/2110.02600) \\
Seanie Lee\*, **Hae Beom Lee\***, Juho Lee, Sung Ju Hwang \\
(\*: equal contribution) \\
<span style="color:darkred">**ICLR**</span> 2022

- <font size="4">Meta-Learning Low Rank Covariance Factors for Energy-Based Deterministic Uncertainty</font>
[[paper]](https://arxiv.org/abs/2110.06381) \\
Jeffrey Ryan Willette, **Hae Beom Lee**, Juho Lee, Sung Ju Hwang \\
<span style="color:darkred">**ICLR**</span> 2022

- <font size="4">Large-Scale Meta-Learning with Continual Trajectory Shifting</font>
[[paper]](https://arxiv.org/pdf/2102.07215.pdf) [[code]](https://github.com/JWoong148/ContinualTrajectoryShifting) \\
Jaewoong Shin\*, **Hae Beom Lee\***, Boqing Gong, Sung Ju Hwang \\
(\*: equal contribution) \\
<span style="color:darkred">**ICML**</span> 2021

- <font size="4">MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and Architectures</font>
[[paper]](https://papers.nips.cc/paper/2020/file/84ddfb34126fc3a48ee38d7044e87276-Paper.pdf) [[code]](https://github.com/JWoong148/metaperturb) \\
Jeongun Ryu\*, Jaewoong Shin\*, **Hae Beom Lee\***, Sung Ju Hwang \\
(\*: equal contribution) \\
<span style="color:darkred">**NeurIPS**</span> 2020 <span style="color:darkred">**(spotlight)**</span>

- <font size="4">Meta-Learning for Short Utterance Speaker Recognition with Imbalance Length Pairs</font>
[[paper]](https://arxiv.org/pdf/2004.02863.pdf) [[code]](https://github.com/seongmin-kye/meta-SR) \\
Seong Min Kye, Youngmoon Jung, **Hae Beom Lee**, Sung Ju Hwang, and Hoirin Kim \\
<span style="color:darkred">**Interspeech**</span> 2020

- <font size="4">Meta Variance Transfer: Learning to Augment from the Others</font>
[[paper]](https://proceedings.icml.cc/static/paper_files/icml/2020/2222-Paper.pdf) \\
Seong Jin Park, Seungju Han, Ji-won Baek, Insoo Kim, Juhwan Song, **Hae Beom Lee**, Jae-Joon Han and Sung Ju Hwang \\
<span style="color:darkred">**ICML**</span> 2020

- <font size="4">Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks</font>
[[paper]](https://openreview.net/pdf?id=rkeZIJBYvr) [[code]](https://github.com/haebeom-lee/l2b) \\
**Hae Beom Lee\***, Hayeon Lee\*, Donghyun Na\*, Saehoon Kim, Minseop Park, Eunho Yang, Sung Ju Hwang \\
(\*: equal contribution) \\
<span style="color:darkred">**ICLR**</span> 2020 <span style="color:darkred">**(oral presentation)**</span>

- <font size="4">Meta Dropout: Learning to Perturb Latent Features for Generalization</font>
[[paper]](https://openreview.net/pdf?id=BJgd81SYwr) [[code]](https://github.com/haebeom-lee/metadrop) \\
**Hae Beom Lee**, Taewook Nam, Eunho Yang, Sung Ju Hwang \\
<span style="color:darkred">**ICLR**</span> 2020

- <font size="4">DropMax: Adaptive Variational Softmax</font>
[[paper]](https://arxiv.org/pdf/1712.07834.pdf)[[code]](https://github.com/haebeom-lee/dropmax) \\
**Hae Beom Lee**, Juho Lee, Saehoon Kim, Eunho Yang, Sung Ju Hwang \\
<span style="color:darkred">**NeurIPS**</span> 2018

- <font size="4">Uncertainty-Aware Attention for Reliable Interpretation and Prediction</font>
[[paper]](https://arxiv.org/pdf/1805.09653.pdf)[[code]](https://github.com/jayheo/UA) \\
Jay Heo\*, **Hae Beom Lee\***, Saehoon Kim, Juho Lee, Kwang Joon Kim, Eunho Yang, Sung Ju Hwang \\
(\*: equal contribution) \\
<span style="color:darkred">**NeurIPS**</span> 2018

- <font size="4">Deep Asymmetric Multi-task Feature Learning</font>
[[paper]](https://arxiv.org/pdf/1708.00260.pdf)[[code]](https://github.com/haebeom-lee/amtfl) \\
**Hae Beom Lee**, Eunho Yang, Sung Ju Hwang \\
<span style="color:darkred">**ICML**</span> 2018

## Workshop Publications

- <font size="4">Meta Mirror Descent: Optimiser Learning for Fast Convergence</font>
[[paper]](https://arxiv.org/pdf/2203.02711.pdf) \\
Boyan Gao, Henry Gouk, **Hae Beom Lee**, Timothy M. Hospedales \\
GroundedML: Workshop on Anchoring Machine Learning in Classical Algorithmic Theory 2022


## Preprints

- <font size="4">Meta-Learned Confidence for Few-shot Learning</font>
[[paper]](https://arxiv.org/pdf/2002.12017.pdf)[[code]](https://github.com/seongmin-kye/MCT) \\
Sung Min Kye, **Hae Beom Lee**, Hoirin Kim, Sung Ju Hwang \\
arXiv, 2020

- <font size="4">Adaptive Network Sparsification with Dependent Variational Beta-Bernoulli Dropout</font>
[[paper]](https://arxiv.org/pdf/1805.10896.pdf)[[code]](https://github.com/OpenXAIProject/Variational_Dropouts) \\
Juho Lee, Saehoon Kim, Jaehong Yoon, **Hae Beom Lee**, Eunho Yang, Sung Ju Hwang \\
arXiv, 2018


## Work Experiences

- Research Intern, The University of Edinburgh, 2021.10 - present (Advisor: **Prof. Timothy Hospedales**.)
- Research Intern, Samsung Research, Korea, 2019.12 - 2020.02
- Research Intern, AITRICS, Korea, 2017. 12 - 2018. 02
